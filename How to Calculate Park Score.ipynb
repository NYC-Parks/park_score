{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Calculate the Park Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data from Open Data\n",
    "- Open Data only lets you read 1000 rows by default. Change the limit `$limit=NUMBER` to make sure you're pulling all the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Parks Inspection Program - Inspections Data](https://data.cityofnewyork.us/dataset/Parks-Inspection-Program-Inspections/yg3y-7juh/about_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parks Inspection Program\n",
    "PIPInspectionMain = pd.read_csv(\"https://data.cityofnewyork.us/resource/yg3y-7juh.csv?$limit=1000000\")\n",
    "PIPInspectionMain = PIPInspectionMain[PIPInspectionMain.inspectiontype == 'PIP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Parks Inspection Program - Feature Ratings](https://data.cityofnewyork.us/City-Government/Parks-Inspection-Program-Feature-Ratings/5mma-5n3h/about_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPFeatureRatings = pd.read_csv(\"https://data.cityofnewyork.us/resource/5mma-5n3h.csv?$limit=3000000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Parks Inspection Program - Public Restroom Inspections](https://data.cityofnewyork.us/City-Government/Parks-Inspection-Program-Public-Restroom-Inspectio/mp8v-wjtf/about_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIP_PRRatings = pd.read_csv(\"https://data.cityofnewyork.us/resource/mp8v-wjtf.csv?$limit=1000000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(group: pd.core.groupby.generic.DataFrameGroupBy) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function normalizes the feature weights within an inspeection. \n",
    "    \n",
    "    Parameters:\n",
    "    - group (pd.core.groupby.generic.DataFrameGroupBy): a groupby group by InspectionID \n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with a new column called normalized_weights where weights are normalized from 0 to 1\n",
    "    \n",
    "    Example:\n",
    "    >>> sample_grouped = sample_df.groupby(\"InspectionID\")\n",
    "    >>> result = sample_grouped.apply(normalize_weights)\n",
    "    \"\"\"\n",
    "    total_weight = group[\"weights\"].sum()\n",
    "    group[\"normalized_weights\"] = group[\"weights\"] / total_weight\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_restroom_inspections(start: str, end: str, rated: pd.DataFrame, PIP_PRRatings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function ingests Public Restroom inspections and filters out unrated data.\n",
    "    \n",
    "    Parameters:\n",
    "    - start (str): start date for the period during which inspections take place in YYYY-MM-DD format, ex. '2020-12-27'\n",
    "    - end (str): end date for the period during which inspections take place in YYYY-MM-DD format, ex. '2023-12-27'\n",
    "    - rated (pd.DataFrame): pd.DataFrame containing inspections \n",
    "        - contains columns: feature_1, prop_id, inspection_id, rating, date\n",
    "    - PIP_PRRatings (pd.DataFrame): pd.DataFrame containing public restroom inspections \n",
    "        - contains columns: inspectionid, csnumber, cs_overall_condition, cs_litter, cs_graffiti, cs_amenities, cs_structural\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with filtered restroom inspections\n",
    "    \n",
    "    Example:\n",
    "    >>> result = filter_restroom_inspections(\"2020-12-27\", \"2023-12-27\", rated, PIP_PRRatings)\n",
    "    \"\"\"\n",
    "    # Take out the ratings that are meant to be closed\n",
    "    restroom_inspections = PIP_PRRatings[PIP_PRRatings[\"cs_overall_condition\"] != \"N\"]\n",
    "\n",
    "    # Take out the ratings for restrooms that were supposed to be open but were not rated because they're closed\n",
    "    restroom_inspections = restroom_inspections[~((restroom_inspections[\"cs_overall_condition\"] == \"U\") & \n",
    "                                                  (restroom_inspections[\"cs_litter\"] == \"N\") & \n",
    "                                                  (restroom_inspections[\"cs_graffiti\"] == \"N\") &\n",
    "                                                  (restroom_inspections[\"cs_amenities\"] == \"N\") & \n",
    "                                                  (restroom_inspections[\"cs_structural\"] == \"N\"))]\n",
    "    \n",
    "    # Take out the ratings where features are not rated, but overall condition is an A\n",
    "    restroom_inspections = restroom_inspections[~((restroom_inspections[\"cs_overall_condition\"] == \"A\") & \n",
    "                                                  (restroom_inspections[\"cs_litter\"] == \"N\") & \n",
    "                                                  (restroom_inspections[\"cs_graffiti\"] == \"N\") &\n",
    "                                                  (restroom_inspections[\"cs_amenities\"] == \"N\") & \n",
    "                                                  (restroom_inspections[\"cs_structural\"] == \"N\"))]\n",
    "\n",
    "    # Drop overall condition columns and clean up df\n",
    "    restroom_inspections = restroom_inspections.drop([\"cs_overall_condition\"], axis = 1)\n",
    "    restroom_inspections = restroom_inspections.set_index([\"inspectionid\", \"csnumber\"]).stack().reset_index()\n",
    "    restroom_inspections = restroom_inspections.rename(columns = {\"level_2\": \"feature\", 0: \"rating\", \"inspectionid\": \"inspection_id\"})\n",
    "    restroom_inspections[\"feature\"] = restroom_inspections[\"feature\"].apply(lambda x: x.split(\"_\")[0].upper() + \" \" + x.split(\"_\")[1].title())\n",
    "\n",
    "    # Find the prop ID and date for restroom inspections\n",
    "    restroom_inspections = pd.merge(restroom_inspections, \n",
    "                                    PIPInspectionMain[[\"prop_id\", \"inspection_id\", \"date\"]], on=\"inspection_id\", how='left')\n",
    "    # Filter dates\n",
    "    restroom_inspections = restroom_inspections[(restroom_inspections['date'] >= start) & \n",
    "                                                (restroom_inspections['date'] <= end)]\n",
    "    \n",
    "    restroom_inspections = restroom_inspections[restroom_inspections['rating'] != \"N\"]\n",
    "    \n",
    "    return restroom_inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_penalties(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes in a filtered rated pd.DataFrame (either for cleanliness, structural, or landscape data) and\n",
    "    calculates Park Score based on the weights\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): contains rated features plus their weights\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with Park Score \n",
    "    \n",
    "    Example:\n",
    "    >>> df = apply_penalties(df)\n",
    "    \"\"\"\n",
    "    df = df.groupby(\"inspection_id\")\n",
    "    df = df.apply(normalize_weights)\n",
    "    df = df.drop('weights', axis = 1)\n",
    "    df = df.rename(columns = {\"normalized_weights\": 'weights'})\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_U_penalty = df[df[\"rating\"] == \"U\"].groupby([\"prop_id\", \"inspection_id\"]).agg(u_penalty=(\"weights\", lambda x: (x * 2).sum())).reset_index()\n",
    "    df_US_penalty = df[df[\"rating\"] == \"U/S\"].groupby([\"prop_id\", \"inspection_id\"]).agg(us_penalty=(\"weights\", lambda x: (x * 6).sum())).reset_index()\n",
    "    df[\"park_score\"] = 1\n",
    "    df = df.drop_duplicates([\"prop_id\", \"inspection_id\", \"date\"])[[\"prop_id\", \"inspection_id\", \"date\", \"park_score\"]]\n",
    "    df = pd.merge(df, df_U_penalty, how=\"left\", on = [\"prop_id\", \"inspection_id\"])\n",
    "    df = pd.merge(df, df_US_penalty, how=\"left\", on = [\"prop_id\", \"inspection_id\"])\n",
    "    df = df.fillna(0)\n",
    "    # Floors the score at 0\n",
    "    df[\"park_score\"] = (df[\"park_score\"] - df[\"u_penalty\"] - df[\"us_penalty\"]).clip(lower = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cleanliness_score(cleanliness: pd.DataFrame, \n",
    "                                cleanliness_weights: dict, \n",
    "                                cleanliness_no_cs_weights: dict,\n",
    "                                cs_number_per_insp_sum: pd.core.series.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes in the rated DataFrame and returns a score based solely on cleanliness features\n",
    "    \n",
    "    Parameters:\n",
    "    - cleanliness (pd.DataFrame): Contains cleanliness features with all their ratings \n",
    "        - contains columns: prop_id, inspection_id, feature, rating, date, inspection_type, csnumber\n",
    "    - cleanliness_weights (dict): dict defining cleanliness features and weights\n",
    "    - cs_number_per_insp_sum (pandas.core.series.Series): the number of public restrooms per inspection (structural includes CS Structural as a feature) \n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with Park Score: contains columns prop_id, inspection_id, date, park_score, f_type\n",
    "    \n",
    "    Example:\n",
    "    >>> df = calculate_cleanliness_score(df, {'Glass': 0.15, 'Graffiti': 0.05, ... }, cs_number_per_insp_sum)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate inspections with 2 CS being inspected - at least 4 restrooms\n",
    "    two_cs = cleanliness[cleanliness[\"inspection_id\"].isin(cs_number_per_insp_sum[cs_number_per_insp_sum == 3].index)]\n",
    "    two_cs[\"weights\"] = two_cs[\"feature\"].map(cleanliness_weights)\n",
    "    # Each CS contributes to the overall restroom score equally\n",
    "    two_cs.loc[two_cs[\"feature\"].isin([\"CS Litter\", \"CS Graffiti\", \"CS Amenities\"]), \"weights\"] = two_cs[two_cs[\"feature\"].isin([\"CS Litter\", \"CS Graffiti\", \"CS Amenities\"])][\"weights\"]/2\n",
    "    two_cs_ratings = apply_penalties(two_cs)\n",
    "   \n",
    "    # Contains 1 CS being inspected \n",
    "    one_no_cs = cleanliness[~cleanliness[\"inspection_id\"].isin(cs_number_per_insp_sum[cs_number_per_insp_sum == 3].index)]\n",
    "    one_cs = one_no_cs[one_no_cs[\"inspection_id\"].isin(set(one_no_cs[one_no_cs[\"csnumber\"].notna()][\"inspection_id\"]))]\n",
    "    one_cs[\"weights\"] = one_cs[\"feature\"].map(cleanliness_weights)\n",
    "    one_cs_ratings = apply_penalties(one_cs)\n",
    "    \n",
    "    # No CS inspected contains different weights \n",
    "    no_cs = one_no_cs[~one_no_cs[\"inspection_id\"].isin(set(one_no_cs[one_no_cs[\"csnumber\"].notna()][\"inspection_id\"]))]\n",
    "    no_cs[\"weights\"] = no_cs[\"feature\"].map(cleanliness_no_cs_weights)\n",
    "    no_cs_ratings = apply_penalties(no_cs)\n",
    "\n",
    "    cleanliness = pd.concat([no_cs_ratings, one_cs_ratings, two_cs_ratings])[[\"prop_id\", \"inspection_id\", \"date\", \"park_score\"]]\n",
    "    cleanliness['f_type'] = 'Cleanliness Only'\n",
    "    \n",
    "    return cleanliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_structural_score(rated: pd.DataFrame, structural_weights: dict, cs_number_per_insp_sum: pd.core.series.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes in the rated DataFrame and returns a score based solely on structural features, \n",
    "    with CS Structural from public restroom inspections\n",
    "    \n",
    "    Parameters:\n",
    "    - rated (pd.DataFrame): Contains structural features with all their ratings \n",
    "        - contains columns: prop_id, inspection_id, feature, rating, date, inspection_type, csnumber\n",
    "    - structural_weights (dict): dict defining structural features and weights\n",
    "    - cs_number_per_insp_sum (pandas.core.series.Series): the number of public restrooms per inspection \n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with Park Score\n",
    "    \n",
    "    Example:\n",
    "    >>> df = calculate_structural_score(df, {'Play Equipment': 0.25, 'Paved Surfaces': 0.25, 'Safety Surface': 0.15,...}, cs_number_per_insp_sum)\n",
    "    \"\"\"\n",
    "    feature_list = list(structural_weights.keys())\n",
    "    structural = rated[rated['feature'].isin(feature_list)]\n",
    "    structural['weights'] = structural['feature'].map(structural_weights)\n",
    "    # Make sure restrooms with two CS are divided by two (spread between the 0.05 for CS Structural) \n",
    "    cs_number_per_insp_sum = structural.drop_duplicates([\"inspection_id\", \"csnumber\"]).groupby([\"inspection_id\"])[\"csnumber\"].sum()\n",
    "    structural.loc[(structural[\"inspection_id\"].isin(cs_number_per_insp_sum[cs_number_per_insp_sum == 3].index)) & (structural[\"feature\"].isin([\"CS Structural\"])), \"weights\"] = structural[(structural[\"inspection_id\"].isin(cs_number_per_insp_sum[cs_number_per_insp_sum == 3].index)) & (structural[\"feature\"].isin([\"CS Structural\"]))][\"weights\"]/2    \n",
    "    structural_ratings = apply_penalties(structural)\n",
    "    structural = structural_ratings[[\"prop_id\", \"inspection_id\", \"date\", \"park_score\"]].drop_duplicates()\n",
    "    structural['f_type'] = 'Structural Only'\n",
    "    \n",
    "    return structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_landscape_score(rated: pd.DataFrame, landscape_weights: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes in the rated DataFrame and returns a score based solely on landscape features\n",
    "    \n",
    "    Parameters:\n",
    "    - rated (pd.DataFrame): Contains landscape features with all their ratings\n",
    "    - landscape_weights (dict): dict defining landscape features and weights\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with Park Score\n",
    "    \n",
    "    Example:\n",
    "    >>> df = calculate_landscape_score(df, {'Lawns': 0.4,'Trees': 0.25,...})\n",
    "    \"\"\"\n",
    "    feature_list = list(landscape_weights.keys())\n",
    "    landscape = rated[rated['feature'].isin(feature_list)]\n",
    "    landscape['weights'] = landscape['feature'].map(landscape_weights)\n",
    "    landscape_ratings = apply_penalties(landscape)\n",
    "    landscape = landscape_ratings[[\"prop_id\", \"inspection_id\", \"date\", \"park_score\"]].drop_duplicates()\n",
    "    landscape['f_type'] = 'Landscape Only'\n",
    "    \n",
    "    return landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_score(final: pd.DataFrame, weights_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function takes in the rated DataFrame and returns a score based solely on cleanliness features\n",
    "    \n",
    "    Parameters:\n",
    "    - final (pd.DataFrame): contains inspections with their park score and feature type (ex. Cleanliness, Structural, Landscape)\n",
    "        - contains columns: prop_id, inspection_id, date, park_score, f_type\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with Park Score: dataframe with a weighted score with all features\n",
    "    \n",
    "    Example:\n",
    "    >>> df = calculate_weighted_score(df)\n",
    "    \"\"\"\n",
    "    final = final.reset_index(drop=True)\n",
    "    \n",
    "    # Calculate weighted \"All\" score\n",
    "    weighted_score = final.copy()\n",
    "    weighted_score[\"weight\"] = 0\n",
    "    weighted_score.loc[weighted_score[\"f_type\"] == \"Cleanliness Only\", \"weight\"] = weights_dict[\"Cleanliness\"]\n",
    "    weighted_score.loc[weighted_score[\"f_type\"] == \"Structural Only\", \"weight\"] = weights_dict[\"Structural\"]\n",
    "    weighted_score.loc[weighted_score[\"f_type\"] == \"Landscape Only\", \"weight\"] = weights_dict[\"Landscape\"]\n",
    "    \n",
    "    wm = lambda x: np.average(x, weights=weighted_score.loc[x.index, \"weight\"])\n",
    "    weighted_score = weighted_score.groupby([\"prop_id\", \"inspection_id\", \"date\"]).agg(weighted_score= (\"park_score\", wm)).reset_index()\n",
    "    weighted_score = weighted_score.rename(columns={\"weighted_score\": \"park_score\"})\n",
    "    weighted_score[\"f_type\"] = \"Cleanliness + Structural + Landscape\"\n",
    "    \n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_PIP_Rating(PIPInspectionMain):\n",
    "    \"\"\"\n",
    "    This function takes in the PIP Inspections data and returns a score based on pass and fail\n",
    "    \n",
    "    Parameters:\n",
    "    - PIPInspectionMain (pd.DataFrame): main inspection data, must contain prop_id, inspection_id, date, overall_condition\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe where the PIP Inspections Score of A (Pass) is a 1 and a U (Fail) is a 0\n",
    "    \n",
    "    Example:\n",
    "    >>> df = calculate_PIP_Rating(df)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a PIP Rating score for comparison\n",
    "    PIPRating = PIPInspectionMain[[\"prop_id\", \"inspection_id\", \"date\", \"overall_condition\"]]\n",
    "    PIPRating = PIPRating[(PIPRating['date'] >= start) & (PIPRating['date'] <= end)]\n",
    "    PIPRating = PIPRating[PIPRating[\"overall_condition\"] != \"N\"]\n",
    "    PIPRating[\"park_score\"] = PIPRating[\"overall_condition\"].map({\"A\": 1, \"U\": 0})\n",
    "    PIPRating[\"f_type\"] = \"Inspection Passing Rate\"\n",
    "    PIPRating = PIPRating.drop(\"overall_condition\", axis=1)\n",
    "    \n",
    "    return PIPRating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Park Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_park_score(start: str, end: str, \n",
    "                           cleanliness_weights: dict, \n",
    "                           cleanliness_no_cs_weights: dict,\n",
    "                           structural_weights: dict,\n",
    "                           landscape_weights: dict,\n",
    "                           weights_dict = {\"Cleanliness\": 0.5, \"Structural\": 0.3, \"Landscape\": 0.2}) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function calculates the park score. It assumes global variables \n",
    "    PIPInspectionMain, PIPFeatureRatings, PIP_PRRatings which are\n",
    "    the PIP Inspection overall ratings, feature ratings, and PIP Public Restroom Ratings, respectively.\n",
    "    PIPInspectionMain must contain these columns: inspection_id, date of inspection, and prop_id of \n",
    "    where the inspection took place. PIPFeatureRatings must contain these columns: inspection_id, feature_1, and rating.\n",
    "    PIP_PRRatings must contain these columns: inspectionid, csnumber (number of public restrooms, \n",
    "    where 1 represents a men's and women's restroom), and scores for each feature, cs_overall_condition, \n",
    "    cs_litter, cs_graffiti, cs_amenities, cs_structural.\n",
    "    \n",
    "    Parameters:\n",
    "    - start (str): start date for inspections data ex. '2020-12-27'\n",
    "    - end (str): end date for inspections data, ex. '2020-12-27'\n",
    "    - cleanliness_weights (dict): defines weights for every cleanliness features including restrooms\n",
    "    - cleanliness_no_cs_weights (dict): defines weights for cleanliness features without restrooms\n",
    "    - structural_weights (dict): defines weights to structural features\n",
    "    - landscape_weights (dict): defines weights for landscape features\n",
    "    - weights_dict (dict): defines weights for overall cleanliness, structural, and landscape categories\n",
    "    \n",
    "    Returns:\n",
    "    - pandas Dataframe with a Feature Type and overall Park Score from 0 to 100 per Inspection\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Merge inspections and restroom inspections data\n",
    "    # Merge feature and inspection ratings\n",
    "    inspections = pd.merge(PIPFeatureRatings, PIPInspectionMain, on = \"inspection_id\")\n",
    "    # Filter any features not rated\n",
    "    rated = inspections[inspections['rating'] != \"N\"]\n",
    "    # Select only columns needed\n",
    "    rated = rated[[\"feature_1\", \"prop_id\", \"inspection_id\", \"rating\", \"date\"]]\n",
    "    rated = rated.rename(columns = {\"feature_1\": \"feature\"})\n",
    "    # Filter dates\n",
    "    rated = rated[(rated['date'] >= start) & (rated['date'] <= end)]\n",
    "\n",
    "    # Clean Restroom Inspections Data\n",
    "    restroom_inspections = filter_restroom_inspections(start, end, rated, PIP_PRRatings)\n",
    "     # Filter out restroom inspections that aren't in the main inspections \n",
    "    restroom_inspections= restroom_inspections[~restroom_inspections[\"inspection_id\"].isin(set(restroom_inspections[\"inspection_id\"]) - set(rated[\"inspection_id\"]))]\n",
    "    # Define Inspection Type\n",
    "    rated[\"inspection_type\"] = \"Inspection\"\n",
    "    restroom_inspections[\"inspection_type\"] = \"Inspection with Restroom\"\n",
    "    \n",
    "    # Concatenate everything\n",
    "    rated = pd.concat([rated, restroom_inspections])\n",
    "    rated[\"rating\"] = rated[\"rating\"].str.upper()\n",
    "    \n",
    "    # Differentiate Inspection Types\n",
    "    allIDs = set(rated[\"inspection_id\"])\n",
    "    restroomIDs = set(rated[rated[\"inspection_type\"] == \"Inspection with Restroom\"][\"inspection_id\"])\n",
    "    inspectionIDs = allIDs - restroomIDs\n",
    "    IDmappings = pd.DataFrame(pd.concat([pd.Series(\"Inspection\", index=inspectionIDs), pd.Series(\"Inspection with Restroom\", index=restroomIDs)])).reset_index()\n",
    "    IDmappings = IDmappings.rename(columns = {\"index\": \"inspection_id\", 0: \"inspection_type\"})\n",
    "    \n",
    "    ### Calculate Cleanliness, Structural, and Landscape Scores\n",
    "    # create table of ratings based only on cleanliness, then only structural, then only landscape\n",
    "    cleanliness = rated[rated[\"feature\"].isin(list(cleanliness_weights.keys()))]\n",
    "    cs_number_per_insp_sum = cleanliness.drop_duplicates([\"inspection_id\", \"csnumber\"]).groupby([\"inspection_id\"])[\"csnumber\"].sum()\n",
    "    \n",
    "    cleanliness = calculate_cleanliness_score(cleanliness, cleanliness_weights, cleanliness_no_cs_weights, cs_number_per_insp_sum)\n",
    "    structural = calculate_structural_score(rated, structural_weights, cs_number_per_insp_sum)\n",
    "    landscape = calculate_landscape_score(rated, landscape_weights)\n",
    "    \n",
    "    \n",
    "    ### Concatenate 3 feature type tables with overall calculated score\n",
    "    final = pd.concat([cleanliness, structural, landscape])\n",
    "    weighted_score = calculate_weighted_score(final, weights_dict)\n",
    "    PIPRating = calculate_PIP_Rating(PIPInspectionMain)\n",
    "    final = pd.concat([final, weighted_score, PIPRating])\n",
    "    final = final.reset_index(drop=True)\n",
    "    final[\"park_score\"] = final[\"park_score\"] * 100\n",
    "    \n",
    "   \n",
    "    final = pd.merge(final, IDmappings, how=\"left\", on = \"inspection_id\")\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Park Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This grabs the scores of all parks starting from today, covering the past 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "rolling_period_year = 3\n",
    "\n",
    "end = (today).strftime(\"%Y-%m-%d\")\n",
    "start = (today - relativedelta(years = rolling_period_year)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for different categories\n",
    "# ice and weeds should switch off and there should never be a ice AND weeds rating\n",
    "cleanliness_weights = {\"Glass\": 0.15, \"Graffiti\": 0.05, \"Ice\": 0.05, \"Weeds\": 0.05, \"Litter\": 0.30, \n",
    "                       \"CS Litter\": 0.25, \"CS Graffiti\": 0.05, \"CS Amenities\": 0.15}\n",
    "# If no CS, it's exactly the same weights for original Cleanliness features \n",
    "cleanliness_no_cs_weights = {\"Glass\": 15/55, \"Graffiti\": 5/55, \"Ice\": 5/55, \"Weeds\": 5/55, \"Litter\": 30/55}\n",
    "\n",
    "structural_weights = {'Play Equipment': 0.25, 'Paved Surfaces': 0.25, 'Safety Surface': 0.15, \n",
    "                      'Benches': 0.15, 'Sidewalks': 0.10, 'CS Structural': 0.05, 'Fences': 0.05}\n",
    "landscape_weights = {\"Lawns\": 0.40, 'Trees': 0.25, 'Athletic Fields': 0.20, \n",
    "                     'Horticultural Areas': 0.05, 'Water Bodies': 0.05, 'Trails': 0.05}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_score = calculate_park_score(start, end, cleanliness_weights, cleanliness_no_cs_weights, structural_weights, landscape_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate to a Park Level from Zone Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Parks Inspection Program – All Sites (MAPPED)](https://data.cityofnewyork.us/City-Government/Parks-Inspection-Program-All-Sites-MAPPED-/buk3-3qpr/about_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllSites = pd.read_csv(\"https://data.cityofnewyork.us/resource/buk3-3qpr.csv?$limit=3000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Park Score to retrieve Parks (PropNum)\n",
    "park_score = pd.merge(park_score, AllSites[[\"prop_name\", \"prop_id\", \"propnum\"]].drop_duplicates(), on='prop_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the score for all\n",
    "park_score_all = park_score[park_score[\"f_type\"] == \"Cleanliness + Structural + Landscape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_score_all.groupby([\"propnum\", \"prop_name\"])[\"park_score\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "park_score_public_test",
   "language": "python",
   "name": "park_score_public_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
